#!/usr/bin/env python3
"""
Sistema de Classifica√ß√£o de V√≠deo em Tempo Real - APENAS V√çDEOS LOCAIS
Classifica entre: break, conteudo, merchan
"""

import cv2
import numpy as np
import time
import threading
import queue
from collections import deque
import argparse
import os
import sys
from pathlib import Path

# Adicionar paths necess√°rios
current_dir = Path(__file__).parent
sys.path.append(str(current_dir))
sys.path.append(str(current_dir.parent / 'common'))

try:
    from video_classifier_simple import SimpleVideoClassifier
except ImportError:
    print("‚ùå Erro: video_classifier_simple.py n√£o encontrado")
    sys.exit(1)

class RealTimeVideoClassifier:
    def __init__(self, model_path, window_seconds=3, fps_target=30):
        """
        Classificador de v√≠deo em tempo real para ARQUIVOS LOCAIS APENAS
        
        Args:
            model_path: Caminho para o modelo treinado
            window_seconds: Janela de tempo para classifica√ß√£o (segundos) - REDUZIDO para 3s
            fps_target: FPS alvo para processamento
        """
        self.model_path = model_path
        self.window_seconds = window_seconds
        self.fps_target = fps_target
        self.frame_interval = max(1, fps_target // 8)  # Processa mais frames (1 a cada 4 frames)
        
        # Carregar classificador
        print(f"ü§ñ Carregando modelo: {model_path}")
        self.classifier = SimpleVideoClassifier()
        
        # Tentar diferentes formatos de caminho
        if os.path.isdir(model_path):
            success = self.classifier.load_model(model_path)
        elif model_path.endswith('.pkl'):
            success = self.classifier.load_model(model_path)
        else:
            if os.path.exists(f"{model_path}.pkl"):
                success = self.classifier.load_model(f"{model_path}.pkl")
            else:
                success = self.classifier.load_model(model_path)
        
        if not success:
            raise Exception(f"‚ùå Erro ao carregar modelo: {model_path}")
        
        # Buffers para frames e classifica√ß√µes
        self.frame_buffer = deque(maxlen=window_seconds * fps_target)
        self.classification_queue = queue.Queue(maxsize=10)
        self.current_classification = {"class": "inicializando", "confidence": 0.0}
        
        # Estado do processamento
        self.processing = False
        self.frame_count = 0
        
        # Cores para cada classe
        self.class_colors = {
            'break': (0, 255, 255),      # Amarelo
            'conteudo': (0, 255, 0),     # Verde
            'merchan': (255, 0, 255),    # Magenta
            'inicializando': (128, 128, 128)  # Cinza
        }
        
        print(f"‚úÖ Classificador iniciado - Janela: {window_seconds}s, FPS: {fps_target}")
    
    def extract_features_from_buffer(self):
        """Extrai features do buffer de frames atual"""
        if len(self.frame_buffer) < 3:  # Reduzido para 3 frames m√≠nimo (mais responsivo)
            return None
            
        # Pegar frames espa√ßados do buffer
        buffer_list = list(self.frame_buffer)
        step = max(1, len(buffer_list) // 12)  # Aumentado para 12 frames para mais detalhes
        selected_frames = buffer_list[::step][:12]
        
        # Converter para formato esperado pelo classificador
        frames_array = np.array(selected_frames)
        
        # Extrair features usando o classificador
        try:
            features = self.classifier.extract_features_from_frames(frames_array)
            return features
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao extrair features: {e}")
            return None
    
    def classification_worker(self):
        """Worker thread para classifica√ß√£o cont√≠nua"""
        while self.processing:
            try:
                # Extrair features do buffer atual
                features = self.extract_features_from_buffer()
                
                if features is not None:
                    # Classificar
                    prediction_idx = self.classifier.classifier.predict([features])[0]
                    probabilities = self.classifier.classifier.predict_proba([features])[0]
                    confidence = max(probabilities)
                    
                    # Converter √≠ndice para nome da classe
                    prediction_class = self.classifier.classes[prediction_idx]
                    
                    # Atualizar classifica√ß√£o atual
                    self.current_classification = {
                        "class": prediction_class,
                        "confidence": confidence,
                        "timestamp": time.time()
                    }
                
                # Aguardar menos tempo para ser mais responsivo
                time.sleep(0.2)  # Classificar a cada 0.2s (5x por segundo)
                
            except Exception as e:
                print(f"‚ö†Ô∏è Erro na classifica√ß√£o: {e}")
                time.sleep(1)
    
    def draw_classification_overlay(self, frame):
        """Desenha overlay com classifica√ß√£o atual"""
        height, width = frame.shape[:2]
        
        # Configura√ß√µes do overlay
        class_name = self.current_classification["class"]
        confidence = self.current_classification["confidence"]
        color = self.class_colors.get(class_name, (255, 255, 255))
        
        # Garantir que class_name seja string
        if isinstance(class_name, (int, np.integer)):
            class_name = self.classifier.classes[int(class_name)] if hasattr(self.classifier, 'classes') else str(class_name)
        class_name = str(class_name)  # For√ßa convers√£o para string
        
        # Caixa de fundo
        overlay_height = 120
        cv2.rectangle(frame, (0, 0), (width, overlay_height), (0, 0, 0), -1)
        cv2.rectangle(frame, (0, 0), (width, overlay_height), color, 3)
        
        # Texto principal
        font = cv2.FONT_HERSHEY_SIMPLEX
        
        # Classe
        class_text = f"CLASSIFICACAO: {class_name.upper()}"
        cv2.putText(frame, class_text, (20, 35), font, 1.2, color, 3)
        
        # Confian√ßa
        conf_text = f"CONFIANCA: {confidence:.1%}"
        cv2.putText(frame, conf_text, (20, 70), font, 0.8, (255, 255, 255), 2)
        
        # Timestamp
        timestamp = time.strftime("%H:%M:%S")
        cv2.putText(frame, timestamp, (width-150, 35), font, 0.7, (255, 255, 255), 2)
        
        # Barra de confian√ßa
        bar_width = int(300 * confidence)
        cv2.rectangle(frame, (20, 85), (20 + bar_width, 105), color, -1)
        cv2.rectangle(frame, (20, 85), (320, 105), color, 2)
        
        # Status do buffer
        buffer_status = f"Buffer: {len(self.frame_buffer)}/{self.frame_buffer.maxlen}"
        cv2.putText(frame, buffer_status, (20, height - 20), font, 0.5, (255, 255, 255), 1)
        
        return frame
    
    def process_video_file(self, video_path):
        """
        Processa arquivo de v√≠deo local
        
        Args:
            video_path: Caminho do arquivo de v√≠deo local
        """
        print(f"üé¨ Iniciando classifica√ß√£o de v√≠deo: {video_path}")
        
        # Verificar se √© webcam ou stream (n√£o suportados)
        if str(video_path) == '0':
            print("‚ùå Webcam n√£o suportada nesta vers√£o")
            return
        elif str(video_path).startswith(('srt://', 'http://', 'https://', 'rtmp://', 'rtsp://')):
            print("‚ùå Streams n√£o suportados nesta vers√£o")
            return
        else:
            print(f"ÔøΩ Tipo: arquivo de v√≠deo local")
            if not os.path.exists(video_path):
                print(f"‚ùå Arquivo n√£o encontrado: {video_path}")
                return
                
            cap = cv2.VideoCapture(video_path)
        
        if not cap.isOpened():
            print(f"‚ùå Erro ao abrir arquivo de v√≠deo: {video_path}")
            return
        
        # Obter informa√ß√µes do v√≠deo
        fps = cap.get(cv2.CAP_PROP_FPS) or 30
        total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        print(f"üìä Resolu√ß√£o: {width}x{height}")
        print(f"üìä FPS: {fps:.1f}")
        if video_path != '0' and video_path != 0:
            duration = total_frames / fps if fps > 0 else 0
            print(f"üìä Dura√ß√£o: {duration:.1f}s ({total_frames:.0f} frames)")
        
        # Calcular delay entre frames para manter velocidade original (apenas arquivos locais)
        frame_delay = 1.0 / fps if fps > 0 else 1.0 / 30.0
        
        print(f"‚è±Ô∏è Delay entre frames: {frame_delay*1000:.1f}ms")
        print(f"üìπ Modo arquivo: respeitando FPS original ({fps:.1f})")
        print("üí° Controles: Q=sair, SPACE=pausar, S=screenshot, R=reiniciar")
        
        # Iniciar thread de classifica√ß√£o
        self.processing = True
        classification_thread = threading.Thread(target=self.classification_worker)
        classification_thread.daemon = True
        classification_thread.start()
        
        # Loop principal de processamento
        frame_count = 0
        last_time = time.time()
        frame_start_time = time.time()
        
        try:
            while True:
                ret, frame = cap.read()
                
                if not ret:
                    if video_path == '0' or video_path == 0:
                        print("‚ö†Ô∏è Perda de conex√£o com v√≠deo")
                        time.sleep(1)
                        continue
                    else:
                        print("üìπ Fim do v√≠deo")
                        break
                
                # Redimensionar frame se muito grande (para display)
                display_frame = frame.copy()
                if width > 1280:
                    scale = 1280 / width
                    new_width = int(width * scale)
                    new_height = int(height * scale)
                    display_frame = cv2.resize(display_frame, (new_width, new_height))
                
                # Adicionar frame ao buffer para classifica√ß√£o
                if frame_count % self.frame_interval == 0:
                    # Redimensionar para processamento (224x224 para o classificador)
                    small_frame = cv2.resize(frame, (224, 224))
                    self.frame_buffer.append(small_frame)
                
                # Desenhar overlay de classifica√ß√£o
                display_frame = self.draw_classification_overlay(display_frame)
                
                # Mostrar frame
                cv2.imshow('Classificacao de Video Local', display_frame)
                
                # Controle de velocidade - respeitar FPS original do arquivo
                elapsed = time.time() - frame_start_time
                remaining_time = frame_delay - elapsed
                if remaining_time > 0:
                    wait_time = int(remaining_time * 1000)  # Convert to milliseconds
                    key = cv2.waitKey(wait_time) & 0xFF
                else:
                    key = cv2.waitKey(1) & 0xFF
                
                frame_start_time = time.time()  # Reset para pr√≥ximo frame
                
                # Controles de teclado
                if key == ord('q'):
                    print("üëã Saindo...")
                    break
                elif key == ord(' '):
                    print("‚è∏Ô∏è Pausado - Pressione SPACE novamente para continuar")
                    cv2.waitKey(0)
                elif key == ord('s'):
                    # Screenshot
                    screenshot_name = f"screenshot_{int(time.time())}.jpg"
                    cv2.imwrite(screenshot_name, display_frame)
                    print(f"üì∏ Screenshot salvo: {screenshot_name}")
                elif key == ord('r'):
                    # Reiniciar v√≠deo
                    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                    print("üîÑ V√≠deo reiniciado")
                
                frame_count += 1
                
                # Mostrar FPS a cada segundo
                current_time = time.time()
                if current_time - last_time >= 1.0:
                    fps_actual = frame_count / (current_time - last_time)
                    buffer_status = f"Buffer: {len(self.frame_buffer)}/{self.frame_buffer.maxlen}"
                    print(f"üìä FPS: {fps_actual:.1f} | Classe: {self.current_classification['class']} ({self.current_classification['confidence']:.1%}) | {buffer_status}")
                    frame_count = 0
                    last_time = current_time
        
        except KeyboardInterrupt:
            print("üëã Interrompido pelo usu√°rio")
        
        finally:
            # Cleanup
            self.processing = False
            cap.release()
            cv2.destroyAllWindows()
            print("‚úÖ Recursos liberados")

def main():
    parser = argparse.ArgumentParser(description="Classificador de V√≠deo - APENAS ARQUIVOS LOCAIS")
    parser.add_argument('--model', required=True, help="Caminho para o modelo treinado")
    parser.add_argument('--source', required=True, help="Arquivo de v√≠deo local")
    parser.add_argument('--window', type=int, default=5, 
                       help="Janela de tempo para classifica√ß√£o (segundos)")
    parser.add_argument('--fps', type=int, default=30, 
                       help="FPS alvo para processamento")
    
    args = parser.parse_args()
    
    # Verificar se modelo existe
    if not os.path.exists(args.model) and not os.path.exists(f"{args.model}.pkl") and not os.path.exists(f"{args.model}/classifier.pkl"):
        print(f"‚ùå Modelo n√£o encontrado: {args.model}")
        return
    
    # Verificar se arquivo de v√≠deo existe
    if (args.source != '0' and 
        not str(args.source).startswith(('srt://', 'http://', 'https://', 'rtmp://', 'rtsp://')) and 
        not os.path.exists(args.source)):
        print(f"‚ùå Arquivo de v√≠deo n√£o encontrado: {args.source}")
        return
    
    try:
        # Criar classificador
        classifier = RealTimeVideoClassifier(
            model_path=args.model,
            window_seconds=args.window,
            fps_target=args.fps
        )
        
        # Processar v√≠deo
        classifier.process_video_file(args.source)
        
    except Exception as e:
        print(f"‚ùå Erro: {e}")

if __name__ == "__main__":
    print("üé¨ === Classificador de V√≠deo LOCAL ===")
    print("Controles:")
    print("  Q - Sair")
    print("  SPACE - Pausar/Retomar")
    print("  S - Screenshot")
    print("  R - Reiniciar v√≠deo (s√≥ arquivos)")
    print()
    
    main()